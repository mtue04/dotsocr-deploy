# Core ML/AI Dependencies
torch==2.7.0
torchvision==0.22.0
transformers==4.51.3
huggingface_hub>=0.20.0
accelerate>=0.25.0
https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1+cu126torch2.7-cp310-cp310-linux_x86_64.whl

# Vision & Image Processing
Pillow>=10.0.0
qwen-vl-utils>=0.0.8

# PDF Processing
PyMuPDF>=1.23.0

# Web Interface
gradio>=4.19.0

# Utilities
requests>=2.31.0
numpy>=1.24.0
